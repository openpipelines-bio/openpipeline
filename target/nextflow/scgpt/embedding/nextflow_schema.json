{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "embedding",
  "description": "Generation of cell embeddings for the integration of single cell transcriptomic count data using scGPT.\n",
  "type": "object",
  "$defs": {
    "Dataset input": {
      "title": "Dataset input",
      "type": "object",
      "description": "Dataset input using nf-tower \"dataset\" or \"data explorer\". Allows for the input of multiple         parameter sets to initialise a Nextflow channel.",
      "properties": {
        "param_list": {
          "description": "Dataset input can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml                 blob. The names of the input fields (e.g. csv columns, json keys) need to be an exact match with the workflow input parameters.",
          "default": "",
          "format": "file-path",
          "mimetype": "text/csv",
          "pattern": "^\\S+\\.csv$"
        }
      }
    },
    "inputs": {
      "title": "Inputs",
      "type": "object",
      "description": "No description",
      "required": [
        "input",
        "model",
        "model_vocab",
        "model_config"
      ],
      "properties": {
        "input": {
          "type": "string",
          "format": "path",
          "exists": true,
          "description": "The input h5mu file containing tokenized gene and count data",
          "help_text": "Type: `file`, multiple: `False`, required, example: `input.h5mu`. "
        },
        "modality": {
          "type": "string",
          "description": "",
          "help_text": "Type: `string`, multiple: `False`, default: `rna`. ",
          "default": "rna"
        },
        "model": {
          "type": "string",
          "format": "path",
          "exists": true,
          "description": "Path to scGPT model file",
          "help_text": "Type: `file`, multiple: `False`, required, example: `best_model.pt`. "
        },
        "model_vocab": {
          "type": "string",
          "format": "path",
          "exists": true,
          "description": "Path to scGPT model vocabulary file",
          "help_text": "Type: `file`, multiple: `False`, required, example: `vocab.json`. "
        },
        "model_config": {
          "type": "string",
          "format": "path",
          "exists": true,
          "description": "Path to scGPT model config file",
          "help_text": "Type: `file`, multiple: `False`, required, example: `args.json`. "
        },
        "obsm_gene_tokens": {
          "type": "string",
          "description": "The key of the ",
          "help_text": "Type: `string`, multiple: `False`, default: `gene_id_tokens`, example: `values.pt`. ",
          "default": "gene_id_tokens"
        },
        "obsm_tokenized_values": {
          "type": "string",
          "description": "The key of the ",
          "help_text": "Type: `string`, multiple: `False`, default: `values_tokenized`. ",
          "default": "values_tokenized"
        },
        "obsm_padding_mask": {
          "type": "string",
          "description": "The key of the ",
          "help_text": "Type: `string`, multiple: `False`, default: `padding_mask`. ",
          "default": "padding_mask"
        },
        "var_gene_names": {
          "type": "string",
          "description": "The name of the ",
          "help_text": "Type: `string`, multiple: `False`. "
        },
        "obs_batch_label": {
          "type": "string",
          "description": "The name of the adata",
          "help_text": "Type: `string`, multiple: `False`. "
        },
        "finetuned_checkpoints_key": {
          "type": "string",
          "description": "Key in the model file containing the pretrained checkpoints",
          "help_text": "Type: `string`, multiple: `False`, example: `model_state_dict`. "
        }
      }
    },
    "outputs": {
      "title": "Outputs",
      "type": "object",
      "description": "No description",
      "required": [
        "output"
      ],
      "properties": {
        "output": {
          "type": "string",
          "format": "path",
          "exists": true,
          "description": "Path to output anndata file containing pre-processed data as well as scGPT embeddings",
          "help_text": "Type: `file`, multiple: `False`, required, default: `$id.$key.output.h5mu`, example: `output.h5mu`. ",
          "default": "$id.$key.output.h5mu"
        },
        "obsm_embeddings": {
          "type": "string",
          "description": "The name of the adata",
          "help_text": "Type: `string`, multiple: `False`, default: `X_scGPT`. ",
          "default": "X_scGPT"
        },
        "output_compression": {
          "type": "string",
          "description": "Compression format to use for the output AnnData and/or Mudata objects",
          "help_text": "Type: `string`, multiple: `False`, example: `gzip`, choices: ``gzip`, `lzf``. ",
          "enum": [
            "gzip",
            "lzf"
          ]
        }
      }
    },
    "arguments": {
      "title": "Arguments",
      "type": "object",
      "description": "No description",
      "required": [],
      "properties": {
        "pad_token": {
          "type": "string",
          "description": "The token to be used for padding",
          "help_text": "Type: `string`, multiple: `False`, default: `<pad>`. ",
          "default": "<pad>"
        },
        "pad_value": {
          "type": "integer",
          "description": "The value of the padding token",
          "help_text": "Type: `integer`, multiple: `False`, default: `-2`. ",
          "default": -2
        },
        "dsbn": {
          "type": "boolean",
          "description": "Whether to apply domain-specific batch normalization for generating embeddings",
          "help_text": "Type: `boolean`, multiple: `False`, default: `true`. ",
          "default": true
        },
        "batch_size": {
          "type": "integer",
          "description": "The batch size to be used for inference\n",
          "help_text": "Type: `integer`, multiple: `False`, default: `64`. ",
          "default": 64
        }
      }
    },
    "nextflow input-output arguments": {
      "title": "Nextflow input-output arguments",
      "type": "object",
      "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
      "required": [],
      "properties": {
        "publish_dir": {
          "type": "string",
          "description": "Path to an output directory",
          "help_text": "Type: `string`, multiple: `False`, required, example: `output/`. "
        }
      }
    }
  },
  "allOf": [
    {
      "$ref": "#/definitions/inputs"
    },
    {
      "$ref": "#/definitions/outputs"
    },
    {
      "$ref": "#/definitions/arguments"
    },
    {
      "$ref": "#/definitions/nextflow input-output arguments"
    }
  ]
}
