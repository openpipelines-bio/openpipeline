functionality:
  name: "process_batches"
  namespace: "workflows/multiomics"
  version: "integration_build"
  authors:
  - name: "Dries Schaumont"
    roles:
    - "author"
    - "maintainer"
    info:
      role: "Core Team Member"
      links:
        email: "dries@data-intuitive.com"
        github: "DriesSchaumont"
        orcid: "0000-0002-4389-0440"
        linkedin: "dries-schaumont"
      organizations:
      - name: "Data Intuitive"
        href: "https://www.data-intuitive.com"
        role: "Data Scientist"
  argument_groups:
  - name: "Inputs"
    arguments:
    - type: "string"
      name: "--id"
      description: "ID of the sample."
      info: null
      example:
      - "foo"
      required: true
      direction: "input"
      multiple: false
      multiple_sep: ":"
      dest: "par"
    - type: "file"
      name: "--input"
      alternatives:
      - "-i"
      description: "Path to the sample."
      info: null
      example:
      - "input.h5mu"
      must_exist: true
      create_parent: true
      required: true
      direction: "input"
      multiple: true
      multiple_sep: ";"
      dest: "par"
    - type: "string"
      name: "--rna_layer"
      description: "Input layer for the gene expression modality. If not specified,\
        \ .X is used."
      info: null
      required: false
      direction: "input"
      multiple: false
      multiple_sep: ":"
      dest: "par"
    - type: "string"
      name: "--prot_layer"
      description: "Input layer for the antibody capture modality. If not specified,\
        \ .X is used."
      info: null
      required: false
      direction: "input"
      multiple: false
      multiple_sep: ":"
      dest: "par"
  - name: "Outputs"
    arguments:
    - type: "file"
      name: "--output"
      description: "Destination path to the output."
      info: null
      example:
      - "output.h5mu"
      must_exist: true
      create_parent: true
      required: true
      direction: "output"
      multiple: false
      multiple_sep: ":"
      dest: "par"
  - name: "Highly variable features detection"
    arguments:
    - type: "string"
      name: "--highly_variable_features_var_output"
      alternatives:
      - "--filter_with_hvg_var_output"
      description: "In which .var slot to store a boolean array corresponding to the\
        \ highly variable genes."
      info: null
      default:
      - "filter_with_hvg"
      required: false
      direction: "input"
      multiple: false
      multiple_sep: ":"
      dest: "par"
    - type: "string"
      name: "--highly_variable_features_obs_batch_key"
      alternatives:
      - "--filter_with_hvg_obs_batch_key"
      description: "If specified, highly-variable genes are selected within each batch\
        \ separately and merged. This simple \nprocess avoids the selection of batch-specific\
        \ genes and acts as a lightweight batch correction method.\n"
      info: null
      default:
      - "sample_id"
      required: false
      direction: "input"
      multiple: false
      multiple_sep: ":"
      dest: "par"
  - name: "QC metrics calculation options"
    arguments:
    - type: "string"
      name: "--var_qc_metrics"
      description: "Keys to select a boolean (containing only True or False) column\
        \ from .var.\nFor each cell, calculate the proportion of total values for\
        \ genes which are labeled 'True', \ncompared to the total sum of the values\
        \ for all genes.\n"
      info: null
      example:
      - "ercc,highly_variable"
      default:
      - "filter_with_hvg"
      required: false
      direction: "input"
      multiple: true
      multiple_sep: ";"
      dest: "par"
    - type: "integer"
      name: "--top_n_vars"
      description: "Number of top vars to be used to calculate cumulative proportions.\n\
        If not specified, proportions are not calculated. `--top_n_vars 20,50` finds\n\
        cumulative proportion to the 20th and 50th most expressed vars.\n"
      info: null
      default:
      - 50
      - 100
      - 200
      - 500
      required: false
      direction: "input"
      multiple: true
      multiple_sep: ";"
      dest: "par"
  - name: "PCA options"
    arguments:
    - type: "boolean_true"
      name: "--pca_overwrite"
      description: "Allow overwriting slots for PCA output."
      info: null
      direction: "input"
      dest: "par"
  resources:
  - type: "nextflow_script"
    path: "main.nf"
    is_executable: true
    entrypoint: "run_wf"
  - type: "file"
    path: "src/workflows/utils/"
  - type: "file"
    path: "./src/workflows/utils/labels.config"
    dest: "nextflow_labels.config"
  description: "This workflow serves as an entrypoint into the 'full_pipeline' in\
    \ order to\nre-run the multisample processing and the integration setup. An input\
    \ .h5mu file will \nfirst be split in order to run the multisample processing\
    \ per modality. Next, the modalities\nare merged again and the integration setup\
    \ pipeline is executed. Please note that this workflow\nassumes that samples from\
    \ multiple pipelines are already concatenated. \n"
  test_resources:
  - type: "nextflow_script"
    path: "test.nf"
    is_executable: true
    entrypoint: "test_wf"
  - type: "nextflow_script"
    path: "test.nf"
    is_executable: true
    entrypoint: "test_wf2"
  - type: "file"
    path: "resources_test/concat_test_data"
  - type: "file"
    path: "resources_test/10x_5k_anticmv"
  - type: "file"
    path: "src/base/openpipelinetestutils"
    dest: "openpipelinetestutils"
  info: null
  status: "enabled"
  requirements:
    commands:
    - "ps"
  dependencies:
  - name: "dataflow/merge"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/dataflow/merge/config.vsh.yml"
    configInfo:
      functionalityName: "merge"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/dataflow/merge/config.vsh.yml"
      functionalityNamespace: "dataflow"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/dataflow/merge/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/dataflow/merge"
  - name: "workflows/multiomics/split_modalities"
    alias: "split_modalities_workflow"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/split_modalities/config.vsh.yaml"
    configInfo:
      functionalityName: "split_modalities"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/split_modalities/config.vsh.yaml"
      functionalityNamespace: "workflows/multiomics"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/workflows/multiomics/split_modalities/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/multiomics/split_modalities"
  - name: "workflows/prot/prot_multisample"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/workflows/prot/prot_multisample/config.vsh.yaml"
    configInfo:
      functionalityName: "prot_multisample"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/workflows/prot/prot_multisample/config.vsh.yaml"
      functionalityNamespace: "workflows/prot"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/workflows/prot/prot_multisample/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/prot/prot_multisample"
  - name: "workflows/rna/rna_multisample"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/workflows/rna/rna_multisample/config.vsh.yaml"
    configInfo:
      functionalityName: "rna_multisample"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/workflows/rna/rna_multisample/config.vsh.yaml"
      functionalityNamespace: "workflows/rna"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/workflows/rna/rna_multisample/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/rna/rna_multisample"
  - name: "workflows/multiomics/dimensionality_reduction"
    alias: "dimensionality_reduction_rna"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/dimensionality_reduction/config.vsh.yaml"
    configInfo:
      functionalityName: "dimensionality_reduction"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/dimensionality_reduction/config.vsh.yaml"
      functionalityNamespace: "workflows/multiomics"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/workflows/multiomics/dimensionality_reduction/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/multiomics/dimensionality_reduction"
  - name: "workflows/multiomics/dimensionality_reduction"
    alias: "dimensionality_reduction_prot"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/dimensionality_reduction/config.vsh.yaml"
    configInfo:
      functionalityName: "dimensionality_reduction"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/dimensionality_reduction/config.vsh.yaml"
      functionalityNamespace: "workflows/multiomics"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/workflows/multiomics/dimensionality_reduction/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/multiomics/dimensionality_reduction"
  - name: "transfer/publish"
    repository:
      type: "local"
      localPath: ""
    foundConfigPath: "/home/runner/work/openpipeline/openpipeline/src/transfer/publish/config.vsh.yaml"
    configInfo:
      functionalityName: "publish"
      git_tag: ""
      git_remote: "https://github.com/openpipelines-bio/openpipeline"
      viash_version: "0.8.5"
      config: "/home/runner/work/openpipeline/openpipeline/src/transfer/publish/config.vsh.yaml"
      functionalityNamespace: "transfer"
      output: ""
      platform: ""
      git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
      executable: "/nextflow/transfer/publish/main.nf"
    writtenPath: "/home/runner/work/openpipeline/openpipeline/target/nextflow/transfer/publish"
  set_wd_to_resources_dir: false
platforms:
- type: "nextflow"
  id: "nextflow"
  directives:
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      mem1gb: "memory = 1.GB"
      mem2gb: "memory = 2.GB"
      mem4gb: "memory = 4.GB"
      mem8gb: "memory = 8.GB"
      mem16gb: "memory = 16.GB"
      mem32gb: "memory = 32.GB"
      mem64gb: "memory = 64.GB"
      mem128gb: "memory = 128.GB"
      mem256gb: "memory = 256.GB"
      mem512gb: "memory = 512.GB"
      mem1tb: "memory = 1.TB"
      mem2tb: "memory = 2.TB"
      mem4tb: "memory = 4.TB"
      mem8tb: "memory = 8.TB"
      mem16tb: "memory = 16.TB"
      mem32tb: "memory = 32.TB"
      mem64tb: "memory = 64.TB"
      mem128tb: "memory = 128.TB"
      mem256tb: "memory = 256.TB"
      mem512tb: "memory = 512.TB"
      cpu1: "cpus = 1"
      cpu2: "cpus = 2"
      cpu5: "cpus = 5"
      cpu10: "cpus = 10"
      cpu20: "cpus = 20"
      cpu50: "cpus = 50"
      cpu100: "cpus = 100"
      cpu200: "cpus = 200"
      cpu500: "cpus = 500"
      cpu1000: "cpus = 1000"
    script:
    - "includeConfig(\"nextflow_labels.config\")"
  debug: false
  container: "docker"
info:
  config: "/home/runner/work/openpipeline/openpipeline/src/workflows/multiomics/process_batches/config.vsh.yaml"
  platform: "nextflow"
  output: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/multiomics/process_batches"
  executable: "/home/runner/work/openpipeline/openpipeline/target/nextflow/workflows/multiomics/process_batches/main.nf"
  viash_version: "0.8.5"
  git_commit: "34ac21de4232f632f4f7043cc87f995fe193450e"
  git_remote: "https://github.com/openpipelines-bio/openpipeline"
